1

绪论

1.1 研究背景及意义

文本纠错是自然语言处理中的一个非常重要的任务，可以应用在几乎所有的 文本处理领域， 文本纠错从纠错对象角度可以分为针对单词/错别字的拼写检查 （Spell Check，SC）和语法错误检测（Grammatical Error Diagnosis，GED）与改正 （Grammatical Error Correction，GEC）。

其中，对于中文文本的纠错中，尤以中文拼写纠错（Chinese Spelling Correction， CSC）更为重要，这是因为相对于语法错误来说，拼写错误可能在更多的场景出现。 在很多中文 NLP 相关的落地场景都会涉及到中文拼写纠错技术的应用，例如跟各 种形式机器人的语音或者文字对话，或者用手机扫描相关的 PDF 或者图片，或者 跟人聊天时用输入法打字等等，无论是通过 ASR 识别的语音信息（可能出现近音 字错误），通过 OCR 识别得到的图片信息（可能出现近形字错误），还是用户通过 输入法键入计算机的文字（可能出现输入错误），都有可能出现错误，并且在上述 场景中这些错误更倾向于是拼写错误，而不是语法错误。这些拼写错误会影响文 本的可读性，不利于人和机器的理解，如果这些错误不加处理，会传播到后续的 环节，且错误可能会被放大，影响后续任务的效果。本课题就是在这样的背景下， 研究中文自动拼写纠错技术。

中文相对于英语等字母（alphabetic）线性（linear）语言，具有很多不同的特 征，这些特征会直接影响到纠错方法的设计方式以及纠错的难度。例如，由于中文 特殊的编码方式，能够在计算机系统内表示的汉字，一定是已编码过的汉字，不 像英文拼写错误会出现错误的未知单词。同时，中文通常由许多没有分词符的字 符组成，这使得 CSC 系统必须根据上下文信息识别拼写错误，而不是仅仅依靠单 个单词或字符。此外，汉字同时具有多种元素——字形、字音、字义，这三者同时 也是导致汉字之间相互混淆而产生拼写错误的重要原因 [1]。根据 Liu 等人（2010） [2] 的研究，大约 83% 的错误与语音相似性有关，48% 与视觉相似性有关。因此， 中文拼写纠错方法必须同时考虑字形（视觉）、字音（听觉）、字义（语义）信息， 才能较好的完成纠错任务。

本课题的研究结果对于促进中文写作辅助、机器翻译、光学字符识别 [3]、自动语音识别 [4]、搜索优化 [5] 等的应用具有积极的意义。

1.2 中文拼写纠错研究现状及相关工作

目前国外针对拼写纠错的研究主要限于英语等字母线性语言，考虑到中文拼 音、字形的特性，同样的方法直接移植到中文上效果并不好。针对中文的拼写纠 错研究主要由国内学者进行，近年来，国内的学者也在积极探索针对中文特点的 拼写纠错方法。

在中文拼写纠错的模型算法方面，Kai Fu 等（2018）[6] 将中文拼写纠错视为 机器翻译任务，利用 transformer 在字级别模型和词级别模型上分别进行机器翻译， 得到正确的句子。Dingmin Wang 等（2019）[7] 提出一个 seq2seq 模型，同时学习如 何从原文本复制一个正确的字或者从混淆集中生成一个候选字，中文的错别字多 在形状或发音上有相似之处，通过混淆集可以进一步约束纠错的结果，防止纠错 的不可控。Yuzhong Hong 等（2019）[8] 用 BERT 为基础的 DAE 取代了传统的混淆 集，同时使用置信度-相似度的解码器来过滤候选集，从而提高纠错效果。Shaohua Zhang 等（2020）[9] 提出的 Soft-Masked BERT 相比直接采用预训练模型 BERT，利 用检测网络从而得到更合理的 soft-masked embedding，缓解了 Bert 缺乏充足检测 能力的问题，虽然改动不大，但是效果提升明显。Xingyi Cheng 等（2020）[10] 采 用图卷积网络将汉字的相似性信息集成到了模型中，在纠错任务中考虑了字形视 觉信息。DCN 将单字的拼音转换为一个独特的整数进行编码加入模型中，使模型 掌握拼音信息。并且在预测阶段通过拼音生成 top K 的备选单字，最终解码获得最 优路径。Shulin Liu 等（2022）[11] 为每个训练样本构建一个嘈杂的上下文，然后 使校正模型被迫根据噪声和原始上下文产生相似的输出，缓解了模型难以处理一 句话存在多个错误的问题，同时引入复制机制，缓解了 Bert 过度矫正的问题。

在中文拼写纠错的数据集方面，SIGHAN15 (Tseng et al., 2015) 收集了在台湾 进行的基于计算机的对外汉语考试 (TOCFL）的作文部分作为语料，并让汉语母语 者进行人工标注，得到了精准度很高并且贴近实际错误的高精度数据集。类似的 数据集还有 SIGHAN14、SIGHAN13 数据集。而人工标注的问题是无法获取巨量 数据，为了解决人工标注数据较少的问题，A Hybrid Approach to Automatic Corpus Generation for Chinese Spelling Check (Dingmin Wang et al., 2018) 通过采集 OCR 和 ASR 的数据获取近音和近形字数据集，通过使用该混淆集，可以自动在任何数据 下生成大量的错误-正确的句子对。


1.3 难点及本课题研究内容

1.3.1 难点

拼写纠错需要全面掌握词的相似度学习、语言建模和推理，使其成为 NLP 中 最具挑战性的任务之一。目前，中文拼写纠错任务的主要难题为：

• 对汉字字形、字音、语义等信息利用不充分，导致纠错效果不佳。如果未考 虑字音、字形信息，现有预训练语言模型会更倾向于使用语义上更常见的字 而不是采用混淆字 (字音、字形相近的字) 纠正错字，这样很可能不符合写作 者原意。

• 由于中文拼写纠错数据需要乏味繁冗的专业人力工作，中文拼写纠错的标注 语料一直稀缺。且训练数据集不能模拟人类所有的犯错情况，训练出的模型 泛化能力差且会发生过拟合。

• 多错误文本 (即包含多个错误的句子) 会影响模型对于语义的理解，导致纠错 性能下降。

• 现有模型无法正确区分实体以及成语等俗语，包含在这些实体和成语中的错 误较难纠正。

1.3.2 本课题研究内容

针对以上难题，本课题的主要研究内容为：

• 研究引入汉字的拼音、字形等信息的方法，引导模型使用混淆字而不是语义 常见字来纠正错字。

• 研究数据增强的方法，尽可能生成贴近中文拼写纠错任务的数据，缓解训练 数据不足的问题。

• 研究处理多错误文本的方法，让模型利用含有错误的上下文信息正确纠错。

• 研究实体纠错和成语等俗语纠错方法。

1.4 主要工作和创新点

本课题的主要工作和创新点是：

• 将拼音编码加入 Transformer Encoder 中强化模型对拼音的识别。

• 使用迭代纠错的方式，将纠正多错误文本转换为多次纠正单错误文本。

• 使用字音、字形混淆集扩充数据集，引入拼音、字形信息，增强了模型的预测能力。

• 使用困惑度验证的方法减少纠错任务中的误召回。

• 使用多种后处理方法串联提升纠错效果。


2 方法

2.1 系统流程图

模型预训练及微调

迭代纠错

困惑度检查

利用 Bad Cases 扩充混淆集

实体 & 成语纠错

N-gram 补充结果

领域内模型补充结果

扩充实体词典

输出结果

2.2 Phonetic-BERT 模型

2.2.1 传统 BERT 模型及其弊端

BERT 使用大规模的未标注语料库进行预训练，从而学习得到通用的语言表 示。其中，BERT 的预训练包括两个任务：

• 掩码语言模型（Masked Language Model，MLM）：模型随机地在输入文本中 替换其中的某些单词，并尝试根据其上下文预测这些被替换的单词。

• 下一句预测（Next Sentence Prediction，NSP）：评估模型是否能够正确地预测 输入的两个句子是否是逻辑上相邻的。 这两个任务的目的是使 BERT 模型能够“理解”句子的语义和句子之间的关系，从而在下游任务中进行迁移学习。 BERT 等预训练语言模型在多个 NLP 任务中表现出色，但是它却不能直接用 来做中文拼写纠错任务，论文 The Past Mistake is the Future Wisdom: Error-driven Contrastive Probability Optimization for Chinese Spell Checking 提到，类似 BERT 的 预训练语言模型，因为其预训练语料的分布 (预训练语料中混淆字占比较少) 以及 训练范式 (通过 [MASK] 标记随机遮盖，进一步降低预测的混淆字占比)，其学习的 知识和 CSC 任务的目标之间存在差距。预训练语言模型更关注文本中的语义，倾 向于将错误的字符更正为语义上正确或常用的字符，但这些并不是正确的校正结 果。

2.2.2 模型设计思路

那么，如何利用预训练语言模型强大的语义理解能力并同时解决混淆字预测 率低的问题呢？最近的很多研究在探索利用预训练的深度学习模型来解决中文拼写纠错问题。 Hong 等人（2019）使用预训练语言模型 BERT（Devlin 等人，2019）生成候选单 词，并使用带有拼音特征的分类器选择最终的纠正结果。Wang 等人（2019）将中 文拼写纠错视为序列到序列的任务，并从混淆集中生成候选项，而不是从整个词汇表中生成。这些方法将拼音信息作为外部知识，但离散的候选项选择使得语言 模型无法直接通过反向传播学习。Zhang 等人（2020）通过修改 BERT 的遮盖机制 提出了一个端到端的中文拼写纠错模型。然而，他们没有使用任何拼音信息，而 这对于探索词语相似性是很重要的。可以看到，上述的工作中要么不使用拼音信 息，要么将拼音信息作为外部知识，没有很好地将拼音信息与预训练语言模型结 合。一个很好的思路是将拼音信息变为预训练阶段的输入。 在本课题中，我使用了 DCN (Wang et al., 2021) 中所采用的拼音编码方法，即将 完整的一个拼音组合编码成一个整数，输入模型中。而后，将拼音经过 Convolutional layer 后的矩阵与文本经过 Eembeding layer 之后的矩阵相加，再输入到 Attention 中， 以此强化拼音编码在模型中的权重。不同于 DCN 中只在 Embedding 阶段将拼音编 码与字符编码相组合，我借鉴了 DeBERTa (He et al, 2020) 中所提及的 Disentangled attention 方法，此过程将在每一次的 Transformer encoder 中进行重复。其公式表示 如下： (2.1)
其中 𝑐 𝑖 是拼音编码，而 ℎ 𝑖 则是汉字字符的编码。 通过对 SIGHAN15 验证集的统计与分析，我发现绝大多数错误都是因为音近 或音近形近导致，而根据 Liu 等人（2010）[2] 的研究，大约 83% 的错误与语音相 似性有关，48% 与视觉相似性有关。同时，考虑到互联网时代下拼音输入法的普 及，网络上储存和传播的中文语料中，拼音相近导致的拼写错误会占大多数。因 此，这里我只引入了汉字的拼音信息，而忽略了字形信息。另外，SIGHAN15 验证 集中的错误表明，存在大量和正确汉字拼音相近但是声调不同的拼写错误，为了 提高模型的运算效率，我也将略去拼音的声调信息，只保留声母和韵母信息。我 采取的这种略去声调的拼音编码的形式比较简单，但其运算效率高，在实际测试 中与复杂的编码方式相比的效果也相近。

2.2.3 模型结构及参数

在本课题中，我的模型在结构上与 Base BERT（Devlin 等人，2019）基本一致， 但在拼音编码部分有所不同。该模型包含了 12 个 Transformer 层，每个隐藏单元 的尺寸为 768。此外，每个 Transformer 层具有 12 个注意力头。在输出层，我将一个全连接层与该结构相拼接，其输入维度为768，输出维度为词汇表大小。最后，
采用 Softmax 函数计算备选词汇的概率分布。

2.2.4 损失函数 (Loss Function) 采用交叉熵作为模型训练和微调的损失函数。该方法是多分类问题中常见的 损失函数，具体公式如下：

2.2.5 优化器 (Optimization) 在本课题中，我选用了 AdamW 优化器（Loshchilov and Hutter，2017）进行模 型训练和微调。AdamW 通过引入权重衰减机制，有效地解决了自适应学习率优化 中的问题。相较于 Adam 优化器（Kingma and Ba，2014）结合 L2 正则化，AdamW 表现出更高的计算效率。

2.3 数据增强

2.3.1 数据增强思路 稀缺的中文拼写纠错数据会降低纠错模型的准确性和鲁棒性。这是因为使用 预训练语言模型处理 CSC 任务时会出现 out of vocabulary 问题，即如果预训练数 据中未包含某个混淆字对，那么预训练模型是不会预测出相应的正确结果的。要 降低 out of vocabulary 的影响，需要将模型在尽可能大的数据集下进行预训练，即 让模型尽可能“见过”某个混淆字对。 我借鉴了 cbert (Liu et al., 2021) 这篇论文的方法，它让中文拼写检查模型在大 规模语料中进行训练和微调，对于无标注数据则采用混淆集自动生成数据的方法 进行构造。cbert 是基于混淆集构造的 bert 模型，由于我需要大量未标注数据扩大 模型训练的数据量，来解决 out of vocabulary 问题，使用混淆集来生成纠错错误对 变得尤为关键。而 cbert 所表述的方法与上述要求一致，所以我采用了该方法，但 是修改了具体的数据生成策略。 原论文采用的策略为：随机从语料中选取 15% 的汉字进行修改，这些选取的 汉字中，60% 的汉字随机替换为语音相似的汉字，15% 的汉字替换为字形相似的汉字，10% 的汉字替换为随机汉字，还有 15% 的汉字保持不变。对于选取的汉字， 若在混淆集中，则按上述比例进行修改; 若不在混淆集中，则保持不变。

由于先前对验证集数据的分析，我认为绝大多数的错误都是音近或音近形近 的错误，所以在使用混淆集进行生成任务时，降低了字形相似替换的比例，以提 升模型的鲁棒性。同时，与原论文不同的是，我在数据生成的过程中保留了一定 比例的正确句子，以降低模型的误纠，这里保留的正确句子比例为 30%。另外，在 数据生成的过程中，我利用生僻字表、停用词表和判断字符是否为中文等策略保 证生成过程中操作的字符为中文且随机替换策略不引入生僻字。最后，由于发现 实体的拼写错误会严重影响句子的语义，我使用序列标注模型判断每个词汇是否 属于实体，实体将保留原始形式而不会引入错误。

原论文和我采用的数据生成策略对比：

表 2.1

原论文数据生成策略

类别

选取比例 语音相似 字形相似 随机替换 不变

比例

15%

60%

15%

10%

15%

表 2.2

修改后的数据生成策略

类别

选取比例 语音相似 字形相似 随机替换 不变

比例

15%

72%

8%

10%

10%

2.3.2 数据增强具体步骤

针对无标注数据集，我采用以下步骤生成自动纠错对：

1. 利用分词算法对原始句子进行分词处理，将其拆分为独立的词汇单元。

2. 应用序列标注模型为所有词汇分配相应的属性标签。

3. 对于被序列标注模型识别为人名、地名等特定类别的词汇（例如某酒店、某公司），保留其原始形式不进行错误生成。此外，非中文词汇和停用词也被 排除在纠错生成过程之外。 4. 按照上述数据生成策略生成数据。

2.4 迭代纠错
在中文拼写纠错研究中，处理包含多个错误的文本一直是一个关键挑战。这 类文本具有一个特点：每个拼写错误的上下文至少包含一个错误的汉字，从而导 致噪声信息。这种嘈杂的环境会导致多错误文本的纠错性能下降。
在先前的研究中，CRASpell (Liu et al., 2022) 通过在训练时在错字周围随机生 成新的错字，模拟了单句中存在多个错误的场景。然而，这种方法可能会对数据 的真实分布产生影响。通常的基于 Transformer 的纠错模型会在每个位置返回概率 最大的汉字，若存在多个错误，则会一并返回。
然而，在预测每个位置的汉字时需要参考上下文信息。如果上下文包含多个 错误，可能导致返回错误的最大概率汉字，从而增加模型的出错概率。为了解决 这个问题，我提出了一种迭代纠错方法。如图所示，具体而言，在预测阶段，如果 一句话中存在多个错误，每次只选取预测错误概率最高的字进行更正，然后将其 放回原句，并进行下一轮纠错，直至不再出现新错误的句子。
以上方表格为例，这个句子中包含连续的四个错字“侯”、“姓”、“青”、“号”，正确
修改应为“候”、“心”、“情”、“好”。因为错误、混乱的上下文信息，第一轮纠错模型 将“青”误纠成了“请”。但是模型在第二轮将“侯”纠正为“候”，在第三轮将“号”纠正为 “好”，最后由于第四轮将“姓”纠正为“心”，上下文信息得到了纠正和完善，本来纠 错的“请”字也被正确修改为“情”。可以看出，上述过程，将单句多错问题转换成了 单句单错字问题，错误、混乱的上下文信息在每一轮纠错后被纠正、补充、完善， 最终恢复正确的语境信息。该迭代纠错方法使得训练与预测的任务更具有一致性， 分布更加统一，并且没有丢弃任何输入信息。

2.5 困惑度检查

在中文拼写检查领域，高误报率同样是一个重要挑战。纠错任务本质上是在 给定位置选择概率最高的字，因此有时可能会错误地修改原本正确的字，即将阴 性样本（无拼写错误）误判为阳性样本（有拼写错误）。部分误报可能源于模型未 充分学习中文拼写纠错知识，导致预测了完全无关的字符，错误较为明显；而另一 部分误报可能导致修改结果仍然较为通顺。例如，模型可能将“我知道他很忙，没有时间跟我联系。”错误地修改为“我知道他很忙，没有时间跟我练习。”。 然而，中文拼写纠错任务的一个基本原则是尽量减少对原句的改动，并保留 原句中没有错误的部分。在上述情况中，都不应发生修改，应保留原句内容。值得 注意的是，无论哪种错误修改情况，原句都应当是合理且通顺的（假设原句作者 书写了合理的句子），理论上正确修改后的句子会变得更为合理通顺。

句子困惑度是衡量概率语言模型对给定句子预测准确性的指标。基于模型为 句子中每个词分配的概率，困惑度评估模型的预测能力。较低的困惑度表示模型 对给定句子的预测不确定性较小，表现更佳。对于同一经过良好训练的模型，较 高困惑度的句子通常意味着模型对这些句子的预测能力较差，可能在语法、语义 或其他方面存在不通顺之处。困惑度反映了模型对句子中每个词分配的概率，较 高的困惑度表示模型在预测这些词时的不确定性较大，这可能源于句子结构复杂、 罕见词汇出现或存在语法错误等原因。因此，可以利用困惑度指标来判断句子是 否经过正确修改，正确修改后的句子的困惑度应仅会降低，而非增加。

我通过对比句子修改前后的困惑度来减少误报的情况，该方法具体的步骤为：

1. 针对一句话，将每个字依次替换为 [MASK]。例如对于句子：我喜欢狗。将被 MASK 成四个 sequence：[MASK] 喜欢狗，我 [MASK] 欢狗，我喜 [MASK] 狗，我喜欢 [MASK]。

2. 将上述四个句子经过 tokenizer 编码后输入进模型。

3. 返回所有 [MASK] 字符对于原字的预测概率。记为 𝑃 = [𝑝 1 , 𝑝 2 , 𝑝 3 , ..., 𝑝 𝑛 ]

4. 𝑙 𝑠𝑐𝑜𝑟𝑒 = 𝑠𝑢𝑚(log 2 𝑝 𝑖 ), where 𝑖 = 1, 2, 3, ..., 𝑛

5. 𝑠𝑐𝑜𝑟𝑒 = 2−𝑙 𝑠𝑐𝑜𝑟𝑒 

𝑠𝑐𝑜𝑟𝑒 较大的句子比 𝑠𝑐𝑜𝑟𝑒 较小的句子更为不通顺。

2.6 实体纠错及成语纠错

2.6.1 实体纠错

在中文拼写纠错任务中，当拼写错误出现在特定类型的命名实体（如人名、地 名、作品名）上时，常规纠错模型往往难以取得理想的性能。这主要是因为纠错模型的学习任务并未包含对命名实体的识别能力，而训练语料也无法涵盖所有可能的命名实体。因此，纠错模型可能会在命名实体上出现错误的纠正或漏报。

命名实体识别（NER）是自然语言处理领域的一个重要任务，它涉及到从文 本中识别出特定类别的实体（如人名、地名、组织名等）。通过将命名实体识别引 入拼写纠错任务，可以帮助模型更好地处理这些特殊类型的实体，从而提高纠错性能。

为了在拼写纠错任务中克服这一挑战，可以考虑将命名实体识别与纠错模型 相结合。具体来说，在纠错过程中，首先利用命名实体识别模型识别出文本中的 实体，然后根据实体类型以及实体是否在已知实体词典中等信息对纠错策略进行 调整。这样可以降低在命名实体上产生错误纠正或漏报的风险，从而提高整体纠 错性能。

2.6.2 成语纠错

成语纠错的原理和实体纠错类似，首先根据拼音相似的条件，匹配到符合条 件的成语，然后再利用语言模型选择最合适的成语或者保留原文。

表 2.5

成语纠错示例

输入 原始修改 成语匹配纠错 分析

他每次穿着奇装衣服，觉得很有意思。 他每次穿着奇装衣服，觉得很有意思。 他每次穿着奇装异服，觉得很有意思。 “奇装衣服”没有改出，通过成语纠错改出

2.7 N-gram 模型补充结果

N-gram 方法是一种无监督的拼写纠错方法，它通过利用无标注语料训练 n 元 语言模型来进行错误检测和纠正。尽管 N-gram 方法在准确率方面的表现通常被认 为是一般的，但可以通过结合过滤策略在一定程度上提高其准确率。

在这种方法中，n 元语言模型捕捉了文本中相邻单词之间的依赖关系，为纠错



过程提供了有价值的信息。然而，N-gram 方法的局限性在于它只能捕捉有限的上 下文信息，因此可能无法充分利用更广泛的语义信息来进行纠错。为了解决这个 问题，可以将 N-gram 方法与过滤策略相结合，进一步优化拼写纠错性能。 过滤策略的引入可以帮助模型关注更为丰富的语义信息，从而提高错误检测 的准确性。同时，它还可以减少由其他纠错方法引入的误纠现象，提高整体纠错 效果。n 元语言模型，可以构建字符串的概率分布 𝑃(𝑊 ), 假设 𝑃 (𝑊 ) 是字符串作 为句子的概率，则概率由下边的公式计算：

𝑃(𝑊 1 𝑊 2 ...𝑊 𝑛 ) = 𝑃(𝑊 𝑖 |𝑊 1 𝑊 2 ...𝑊 𝑖−1 ) ∏ 𝑖

其中 𝑊 𝑖 表示句中第 𝑖 个词，𝑊 1 𝑊 2 ...𝑊 𝑖−1 是 𝑊 𝑖 的“历史”。𝑃(𝑊 4 |𝑊 1 𝑊 2 𝑊 3 ) 表示前 面三个词是 𝑊 1 𝑊 2 𝑊 3 的情况下第四个词是 𝑊 4 的概率。如果共有 5000 个不同的

词，𝑖 = 3 的时候就有 1250 亿个组合，但是因为绝大多数组合根本就不存在，训 练数据或已有语料库数据不可能有这么多组合，所以可以将 𝑊 1 𝑊 2 ...𝑊 𝑖−1 根据规 则映射到等价类，最简单的方法就是取 𝑊 𝑖 之前 𝑛 − 1 个历史，根据马尔科夫假设， 一个词只和他前面 𝑛 − 1 个词相关性最高，这便得到了 n 元语言模型。

𝑃(𝑊 1 𝑊 2 ...𝑊 𝑛 ) ≈ 𝑃(𝑊 𝑖 |𝑊 1 𝑊 2 ...𝑊 𝑖−1 ) ∏ 𝑖

2.8 混淆集及实体词典增强

2.8.1 混淆集增强

在自然语言处理中，一个高效的语言模型应当具备迭代升级的能力，即根据 预测结果与真实值之间的误差不断调整模型参数，以达到更准确的预测。针对上 述预训练范式以及超出词汇表（out of vocabulary）问题，可以通过扩充和增强混 淆集来改进模型表现。

人类的拼写错误可能呈现多种形式，而现有的混淆集未能覆盖所有可能的错 误情况。一个尚未学会某种混淆关系的模型很难预测出正确的修改结果。由于中 国存在多种方言，混淆集无法覆盖所有错误情况的一个主要原因是不同地区可能 存在不同的音近混淆字。因此，很难找到一个包含所有方言的统一混淆字表。

为解决此问题，可以根据实际需求补充混淆集。首先，从模型预测后产生的 错误案例（Bad Case）中提取混淆字对，并将其添加到混淆集中。当无法利用 Bad Case 时，也可以手动补充混淆集。然后，根据上述数据生成策略利用这些混淆字



对生成新的纠错句子对。这些纠错句子对可以用作新的预训练语料，以解决超出 词汇表问题。 在判断 Bad Case 中的音近字时，我采用以下规则：考虑所有多音字情况，若 A 字与 B 字所含拼音字母的差异小于 2 个，则判断为音近字。同时，经过分析发 现，字形相近的错误在总体错误中所占比例较小，因此我没有使用字形相近的 Bad Case 来扩充混淆集。

2.8.2 实体词典增强

考虑到命名实体具有极高的多样性，现有的实体词典很难覆盖所有可能的情 况。为解决这一问题，可以采用类似于混淆集增强的实现思路：在遇到错误案例 （Bad Case）时，若检测到对应的修改部分为一个实体，而模型对该实体进行了错 误的修改，即原文中实体并无错误，可以认定实体词典未包含此实体。随后，将 该实体添加至实体词典中，这样在将来再次遇到该实体时，经过实体纠错处理后， 可以得到正确的预测结果。通过这种方法，我们能够根据模型的错误案例不断扩 充实体词典，提高命名实体识别与纠错的准确性。这种自适应的方式有助于提高 模型在面对未知实体时的鲁棒性，从而更好地适应实际应用场景中的各种情况。

2.9 领域内模型补充结果

在前述研究中，针对拼写错误的修正仅限于通用场景。然而，在特定场景下 的拼写错误处理，例如学科领域文本的拼写纠错和针对外语学习者文本的拼写纠 错等，尚待解决。在这些特定场景下，可能出现特有的错误，而通用模型往往无法 纠正此类错误。

为解决此问题，可构建特定场景下的数据集，并在预训练模型的基础上使用 这些数据集训练专用模型。当输入一个待纠错句子时，首先通过上述通用拼写纠 错流程进行处理，然后将纠错后的结果输入到专用模型中进行再次纠错。这种方 法旨在先处理通用错误，再处理领域相关错误。

专用模型不仅可以解决特定领域的文本纠错问题，还可以用于校正通用模型 的误纠和漏纠。在本研究中，对通用拼写纠错流程的输出结果进行分析，发现模 型无法正确区分汉语中的“的”、“地”和“得”。模型要么无法检测到此类误用错误，要 么会进行错误的纠正。这个问题的主要原因可能是预训练数据集来自互联网中文 语料，无法保证语料的质量。由于许多汉语母语者容易犯此类错误，预训练语料



中可能包含大量此类错误，导致训练出的模型无法纠正这类问题。 为解决这一问题，我构建了一个专用数据集，专门针对“的”、“地”和“得”的正确 使用。该数据集的句子均使用了正确的“的”、“地”和“得”，并在此基础上对预训练模 型进行微调。经过调整后，我得到了一个具有高准确性和鲁棒性的专用模型，用 于应对“的”、“地”和“得”的正确使用问题。最后，我们将模型的输出结果筛选出与 “的”、“地”和“得”相关的纠正，补充并修改通用模型输出的结果，从而实现对通用模 型关于“的”、“地”和“得”的使用问题的有效校正。



3

实验

3.1 预训练

3.1.1 数据

我使用了混淆集过滤后的，从维基百科中抽取的 1-1 的纠错语料共 425568 条。 在微信和新闻语料的基础上，使用混淆集生成的纠错语料共 160 万条。总共得到 超过 200 万的纠错句子对。

3.1.2 参数设置

参考原论文 (Liu et al., 2021)，我们将学习率设置成 5e-5，将 batch size 设置成 64，将最大句子长度设置成 128。

3.2 微调

3.2.1 数据

在微调阶段，我们使用了 SIGHAN15 (Tseng et al., 2015) 的训练数据 5167 条， WANG27 (Dingmin Wang et al.. 2018) 训练数据 271280 条，Hlybrid 训练数据 264946 条。这些训练数据都已经是包含拼写错误的句子对的形式，所以没有使用混淆集 来生成错误。

3.2.2 参数设置

在微调阶段，我们将学习率设置成 [1e-4, 2e-5, 5e-5]，将 batch size 设置成 [16, 32, 64]，将最大句子长度设置成 128。

3.3 实验结果

